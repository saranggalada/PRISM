{"cells":[{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import torch\n","import os\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pickle\n","import sys\n","sys.path.append('..')\n","from model import PRISM\n","from dataset import PRISM_MRI_Dataset\n","sys.path.remove('..')"]},{"cell_type":"markdown","metadata":{},"source":["# Loading Models and Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Model and data initialization\n","'''\n","Harmonization method 1 (preferred): Uniform harmonization - reduces inter-site AND intra-site variations\n","Harmonization method 2: Image-wise harmonization\n","'''\n","harmonization_method = 1\n","data_dir = '/kaggle/input'\n","model_dir = '/kaggle/working'\n","out_dir = f'/kaggle/working/harmonized_{harmonization_method}'\n","modality = 'T2'\n","target='Guys'\n","\n","prism_g = PRISM(intensity_levels=5, latent_dim=2, num_sites=4, gpu_id=0, modality=modality, modalities = ['T2'])\n","prism_h = PRISM(intensity_levels=5, latent_dim=2, num_sites=4, gpu_id=0, modality=modality, modalities = ['T2'])\n","prism_i = PRISM(intensity_levels=5, latent_dim=2, num_sites=4, gpu_id=0, modality=modality, modalities = ['T2'])\n","prism_a = PRISM(intensity_levels=5, latent_dim=2, num_sites=4, gpu_id=0, modality=modality, modalities = ['T2'])\n","\n","# Target site: Guys\n","prism_g.anatomy_encoder.load_state_dict(torch.load(f'{model_dir}/prism-anatomy-encoder_guys.pth', map_location='cpu'))\n","prism_g.style_encoder.load_state_dict(torch.load(f'{model_dir}/prism-style-encoder_guys.pth', map_location='cpu'))\n","prism_g.decoder.load_state_dict(torch.load(f'{model_dir}/prism-decoder_guys.pth', map_location='cpu'))\n","\n","# Source sites: HH, IOP and ADNI\n","prism_h.anatomy_encoder.load_state_dict(torch.load(f'{model_dir}/prism-anatomy-encoder_hh.pth', map_location='cpu'))\n","prism_i.anatomy_encoder.load_state_dict(torch.load(f'{model_dir}/prism-anatomy-encoder_iop.pth', map_location='cpu'))\n","prism_a.anatomy_encoder.load_state_dict(torch.load(f'{model_dir}/prism-anatomy-encoder_adni1.pth', map_location='cpu'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load both train and test datasets for each site\n","guys_ds_train = torch.load(f'{data_dir}/IXI-Guys-train.pt', map_location='cpu')\n","guys_ds_test = torch.load(f'{data_dir}/IXI-Guys-test.pt', map_location='cpu')\n","hh_ds_train = torch.load(f'{data_dir}/IXI-HH-train.pt', map_location='cpu')\n","hh_ds_test = torch.load(f'{data_dir}/IXI-HH-test.pt', map_location='cpu')\n","iop_ds_train = torch.load(f'{data_dir}/IXI-IOP-train.pt', map_location='cpu')\n","iop_ds_test = torch.load(f'{data_dir}/IXI-IOP-test.pt', map_location='cpu')\n","adni_ds_train = torch.load(f'{data_dir}/ADNI1-train.pt', map_location='cpu')\n","adni_ds_test = torch.load(f'{data_dir}/ADNI1-test.pt', map_location='cpu')\n","\n","datasets = {\n","    'Guys': {'model': prism_g, 'data': [(guys_ds_train, 'train'), (guys_ds_test, 'test')]},\n","    'HH': {'model': prism_h, 'data': [(hh_ds_train, 'train'), (hh_ds_test, 'test')]},\n","    'IOP': {'model': prism_i, 'data': [(iop_ds_train, 'train'), (iop_ds_test, 'test')]},\n","    'ADNI1': {'model': prism_a, 'data': [(adni_ds_train, 'train'), (adni_ds_test, 'test')]}\n","}"]},{"cell_type":"markdown","metadata":{},"source":["# Harmonization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Harmonization\n","'''\n","Harmonization method 1 (preferred): Uniform harmonization - reduces inter-site AND intra-site variations\n","Harmonization method 2: Image-wise harmonization\n","'''\n","\n","style_codes = {site: [] for site in datasets.keys()}\n","style_codes_og = {site: [] for site in ['HH', 'IOP', 'ADNI1']}\n","anatomies = {site: [] for site in datasets.keys()}\n","masks = {site: [] for site in datasets.keys()}\n","names = {site: [] for site in datasets.keys()}\n","\n","if harmonization_method == 1:\n","\n","    with torch.set_grad_enabled(False):\n","        # Set all models to eval mode\n","        for site_info in datasets.values():\n","            site_info['model'].anatomy_encoder.eval()\n","            site_info['model'].style_encoder.eval()\n","\n","        # Process each site\n","        for site, site_info in datasets.items():\n","            if not os.path.exists(f'{out_dir}/{site}'):\n","                os.makedirs(f'{out_dir}/{site}')\n","            \n","            for dataset, data_mode in site_info['data']:\n","                for subject in dataset:\n","                    # ... rest of your processing code, using site_info['model'] instead of individual models ...\n","                    image = subject[site_info['model'].modality]['image'].to(site_info['model'].device).unsqueeze(1)\n","                    mask = subject[site_info['model'].modality]['mask'].to(site_info['model'].device).unsqueeze(1)\n","                    _, anatomy = site_info['model'].get_anatomy_representations(image, mask)\n","                    style_code, _, _ = prism_g.get_style_code(image)\n","\n","                    anatomies[site].append(anatomy.detach().squeeze())\n","                    style_codes[site].append(style_code.detach().cpu().squeeze())\n","                    masks[site].append(mask.detach().squeeze())\n","                    names[site].append(subject[site_info['model'].modality]['subject_id'])\n","\n","                    if site != target:\n","                        style_code_og, _, _ = site_info['model'].get_style_code(image)\n","                        style_codes_og[site].append(style_code_og.detach().cpu().squeeze())\n","\n","    # Uniform Harmonization\n","    for site, site_info in datasets.values():\n","        style_code = torch.mean(style_codes[site], dim=0).unsqueeze(1).unsqueeze(1).unsqueeze(0).to(site_info['model'].device)\n","        with torch.set_grad_enabled(False):\n","            prism_g.decoder.eval()\n","\n","            for i in range(len(anatomies[site])):\n","                anatomy = anatomies[site][i].unsqueeze(0).unsqueeze(0)\n","                mask = masks[site][i].unsqueeze(0)\n","                harmonized = prism_g.decode(anatomy, style_code, mask)\n","                subid = names[site][i]\n","                if not os.path.exists(f'{out_dir}/{site}/{data_mode}/{subid}'):\n","                    os.makedirs(f'{out_dir}/{site}/{data_mode}/{subid}')\n","                \n","                plt.imsave(f'{out_dir}/{site}/{data_mode}/{subid}/IXI-{site}-{subid}-{modality}_harmonized.png', harmonized.squeeze().cpu().numpy(), cmap='gray')\n","\n","elif harmonization_method==2:\n","    with torch.set_grad_enabled(False):\n","        # Set all models to eval mode\n","        for site_info in datasets.values():\n","            site_info['model'].anatomy_encoder.eval()\n","        prism_g.style_encoder.eval()\n","        prism_g.decoder.eval()\n","\n","        # Process each site\n","        for site, site_info in datasets.items():\n","            if not os.path.exists(f'{out_dir}/{site}'):\n","                os.makedirs(f'{out_dir}/{site}')\n","            \n","            for dataset, data_mode in site_info['data']:\n","                # Image-level harmonization\n","                for subject in dataset:\n","                    image = subject[site_info['model'].modality]['image'].to(site_info['model'].device).unsqueeze(1)\n","                    mask = subject[site_info['model'].modality]['mask'].to(site_info['model'].device).unsqueeze(1)\n","                    _, anatomy = site_info['model'].get_anatomy_representations(image, mask)\n","                    style_code, _, _ = prism_g.get_style_code(image)\n","                    harmonized = prism_g.decode(anatomy, style_code, mask)\n","                    subid = subject[site_info['model'].modality]['subject_id']\n","                    if not os.path.exists(f'{out_dir}/{site}/{data_mode}/{subid}'):\n","                        os.makedirs(f'{out_dir}/{site}/{data_mode}/{subid}')\n","                    \n","                    plt.imsave(f'{out_dir}/{site}/{data_mode}/{subid}/IXI-{site}-{subid}-{modality}_harmonized.png', harmonized.squeeze().cpu().numpy(), cmap='gray')"]},{"cell_type":"markdown","metadata":{},"source":["# Latent Style Visualization\n","Pre- and Post- Harmonization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# OPTIONAL: Save original and translated latent style codes for each site - for visualization.py\n","if len(style_codes[target])!=0:\n","    for site in datasets.keys():\n","        with open(f'{model_dir}/style_codes_{site.lower()}.pkl', 'wb') as f:\n","            pickle.dump(style_codes[site], f)\n","        if site!=target:\n","            with open(f'{model_dir}/style_codes_{site.lower()}_og.pkl', 'wb') as f:\n","                pickle.dump(style_codes_og[site], f)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'datasets' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m style_codes \u001b[38;5;241m=\u001b[39m {site: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdatasets\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()}\n","\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"]}],"source":["# Stack the style tensor lists for easier handling\n","styles = {site: None for site in datasets.keys()}\n","styles_og = {site: None for site in ['HH', 'IOP', 'ADNI1']}\n","for site in datasets.keys():\n","    styles[site] = torch.stack(style_codes[site])\n","    if site!=target:\n","        styles_og[site] = torch.stack(style_codes[site])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Pre-harmonization latent style visualization\n","\n","plt.figure(figsize=(12, 6))\n","marker = 'P'\n","colours = {'Guys': 'darkcyan',\n","           'HH': 'crimson',\n","           'IOP': 'springgreen',\n","           'ADNI1': 'orange'}\n","for site in datasets.keys():\n","    if site==target:\n","        sns.scatterplot(x=styles[site][:, 0], y=styles[site][:, 1], color=colours[site], marker=marker, label=f'Site {site}', s=50)    \n","    else:\n","        sns.scatterplot(x=styles_og[site][:, 0], y=styles_og[site][:, 1], color=colours[site], marker=marker, label=f'Site {site}', s=50)\n","plt.xlim(-25, 25)\n","plt.ylim(-25, 25)\n","plt.xlabel('Latent Dimension 1')\n","plt.ylabel('Latent Dimension 2')\n","plt.title('Latent Style distributions (pre-harmonization)')\n","plt.legend(fontsize=15)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Post-harmonization latent style visualization\n","\n","plt.figure(figsize=(12, 6))\n","for site in datasets.keys():\n","    sns.scatterplot(x=styles[site][:, 0], y=styles[site][:, 1], color=colours[site], marker=marker, label=f'Site {site}', s=50)\n","plt.xlim(-25, 25)\n","plt.ylim(-25, 25)\n","plt.xlabel('Latent Dimension 1')\n","plt.ylabel('Latent Dimension 2')\n","plt.title('Latent Style distributions (post-harmonization)')\n","plt.legend(fontsize=15)\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5584959,"sourceId":9233484,"sourceType":"datasetVersion"},{"datasetId":5629664,"sourceId":9298275,"sourceType":"datasetVersion"},{"datasetId":5647020,"sourceId":9322221,"sourceType":"datasetVersion"},{"datasetId":5647024,"sourceId":9322225,"sourceType":"datasetVersion"},{"datasetId":5647223,"sourceId":9322454,"sourceType":"datasetVersion"},{"datasetId":5647226,"sourceId":9322458,"sourceType":"datasetVersion"},{"modelId":102721,"modelInstanceId":78153,"sourceId":93235,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
